{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6123d199",
   "metadata": {},
   "source": [
    "<h1>Forecasting</h1><h2 align=\"center\">LSTMs</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d27f352",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m no_grad, tensor\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM, Linear, Module, MSELoss\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from torch import no_grad, tensor\n",
    "from torch.nn import LSTM, Linear, Module, MSELoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "def prepare_dataset_for_lstm(series, seq_length: int = 4):\n",
    "    setX: list = []\n",
    "    setY: list = []\n",
    "    for i in range(len(series) - seq_length):\n",
    "        past = series[i : i + seq_length]\n",
    "        future = series[i + 1 : i + seq_length + 1]\n",
    "        setX.append(past)\n",
    "        setY.append(future)\n",
    "    return tensor(setX), tensor(setY)\n",
    "\n",
    "\n",
    "class DS_LSTM(Module):\n",
    "    def __init__(self, train, input_size: int = 1, hidden_size: int = 50, num_layers: int = 1, length: int = 4):\n",
    "        super().__init__()\n",
    "        self.lstm = LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.linear = Linear(hidden_size, 1)\n",
    "        self.optimizer = Adam(self.parameters())\n",
    "        self.loss_fn = MSELoss()\n",
    "\n",
    "        trnX, trnY = prepare_dataset_for_lstm(train, seq_length=length)\n",
    "        self.loader = DataLoader(TensorDataset(trnX, trnY), shuffle=True, batch_size=len(train) // 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    def fit(self):\n",
    "        self.train()\n",
    "        for batchX, batchY in self.loader:\n",
    "            y_pred = self(batchX)\n",
    "            loss = self.loss_fn(y_pred, batchY)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        return loss\n",
    "\n",
    "    def predict(self, X):\n",
    "        with no_grad():\n",
    "            y_pred = self(X)\n",
    "        return y_pred[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4279eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d75f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, DataFrame, Series\n",
    "from dslabs_functions import series_train_test_split\n",
    "\n",
    "file_tag = \"traffic\"\n",
    "filename = \"../../../data/forecast_traffic_transformed.csv\"\n",
    "index = \"Timestamp\"\n",
    "target = \"Total\"\n",
    "timecol: str = \"Timestamp\"\n",
    "measure: str = \"R2\"\n",
    "\n",
    "data: DataFrame = read_csv(filename, index_col=timecol, sep=\",\", decimal=\".\", parse_dates=True)\n",
    "series = data[[target]].values.astype(\"float32\")\n",
    "\n",
    "train_size = int(len(series) * 0.90)\n",
    "train, test = series[:train_size], series[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e376ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DS_LSTM(train, input_size=1, hidden_size=50, num_layers=1)\n",
    "loss = model.fit()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4890c9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dslabs_functions import HEIGHT, plot_multiline_chart\n",
    "from copy import deepcopy\n",
    "\n",
    "from matplotlib.pyplot import figure, savefig, subplots\n",
    "from dslabs_functions import FORECAST_MEASURES, DELTA_IMPROVE, plot_multiline_chart\n",
    "\n",
    "\n",
    "def lstm_study(train, test, nr_episodes: int = 1000, measure: str = \"R2\"):\n",
    "    sequence_size = [2, 4, 8]\n",
    "    nr_hidden_units = [25, 50, 100]\n",
    "\n",
    "    step: int = nr_episodes // 10\n",
    "    episodes = [1] + list(range(0, nr_episodes + 1, step))[1:]\n",
    "    flag = measure == \"R2\" or measure == \"MAPE\"\n",
    "    best_model = None\n",
    "    best_params: dict = {\"name\": \"LSTM\", \"metric\": measure, \"params\": ()}\n",
    "    best_performance: float = -100000\n",
    "\n",
    "    _, axs = subplots(1, len(sequence_size), figsize=(len(sequence_size) * HEIGHT, HEIGHT))\n",
    "\n",
    "    for i in range(len(sequence_size)):\n",
    "        length = sequence_size[i]\n",
    "        tstX, tstY = prepare_dataset_for_lstm(test, seq_length=length)\n",
    "\n",
    "        values = {}\n",
    "        for hidden in nr_hidden_units:\n",
    "            yvalues = []\n",
    "            model = DS_LSTM(train, hidden_size=hidden)\n",
    "            for n in range(0, nr_episodes + 1):\n",
    "                model.fit()\n",
    "                if n % step == 0:\n",
    "                    prd_tst = model.predict(tstX)\n",
    "                    eval: float = FORECAST_MEASURES[measure](test[length:], prd_tst)\n",
    "                    print(f\"seq length={length} hidden_units={hidden} nr_episodes={n}\", eval)\n",
    "                    if eval > best_performance and abs(eval - best_performance) > DELTA_IMPROVE:\n",
    "                        best_performance: float = eval\n",
    "                        best_params[\"params\"] = (length, hidden, n)\n",
    "                        best_model = deepcopy(model)\n",
    "                    yvalues.append(eval)\n",
    "            values[hidden] = yvalues\n",
    "        plot_multiline_chart(\n",
    "            episodes,\n",
    "            values,\n",
    "            ax=axs[i],\n",
    "            title=f\"LSTM seq length={length} ({measure})\",\n",
    "            xlabel=\"nr episodes\",\n",
    "            ylabel=measure,\n",
    "            percentage=flag,\n",
    "        )\n",
    "    print(\n",
    "        f\"LSTM best results achieved with length={best_params[\"params\"][0]} hidden_units={best_params[\"params\"][1]} and nr_episodes={best_params[\"params\"][2]}) ==> measure={best_performance:.2f}\"\n",
    "    )\n",
    "    return best_model, best_params\n",
    "\n",
    "\n",
    "best_model, best_params = lstm_study(train, test, nr_episodes=3000, measure=measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed71eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dslabs_functions import plot_forecasting_eval\n",
    "\n",
    "params = best_params[\"params\"]\n",
    "best_length = params[0]\n",
    "trnX, trnY = prepare_dataset_for_lstm(train, seq_length=best_length)\n",
    "tstX, tstY = prepare_dataset_for_lstm(test, seq_length=best_length)\n",
    "\n",
    "prd_trn = best_model.predict(trnX)\n",
    "prd_tst = best_model.predict(tstX)\n",
    "\n",
    "plot_forecasting_eval(\n",
    "    train[best_length:],\n",
    "    test[best_length:],\n",
    "    prd_trn,\n",
    "    prd_tst,\n",
    "    title=f\"{file_tag} - LSTM (length={best_length}, hidden={params[1]}, epochs={params[2]})\",\n",
    ")\n",
    "savefig(f\"images/{file_tag}_lstms_{measure}_eval.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288c0f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dslabs_functions import plot_forecasting_series\n",
    "\n",
    "series = data[[target]]\n",
    "train, test = series[:train_size], series[train_size:]\n",
    "pred_series: Series = Series(prd_tst.numpy().ravel(), index=test.index[best_length:])\n",
    "\n",
    "plot_forecasting_series(\n",
    "    train[best_length:],\n",
    "    test[best_length:],\n",
    "    pred_series,\n",
    "    title=f\"{file_tag} - LSTMs \",\n",
    "    xlabel=timecol,\n",
    "    ylabel=target,\n",
    ")\n",
    "savefig(f\"images/{file_tag}_lstms_{measure}_forecast.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
