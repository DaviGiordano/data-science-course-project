{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f864b60",
   "metadata": {},
   "source": [
    "<h1>Classification</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b2654c",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">Decision Trees</h2><h3>Paremeters study</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc506c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from numpy import array, ndarray\n",
    "from matplotlib.pyplot import figure, savefig, show\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from dslabs_functions import CLASS_EVAL_METRICS, DELTA_IMPROVE, read_train_test_from_files\n",
    "from dslabs_functions import plot_evaluation_results, plot_multiline_chart\n",
    "\n",
    "\n",
    "def trees_study(\n",
    "        trnX: ndarray, trnY: array, tstX: ndarray, tstY: array, d_max: int=10, lag:int=2, metric='accuracy'\n",
    "        ) -> tuple:\n",
    "    criteria: list[Literal['entropy', 'gini']] = ['entropy', 'gini']\n",
    "    depths: list[int] = [i for i in range(2, d_max+1, lag)]\n",
    "\n",
    "    best_model: DecisionTreeClassifier | None = None\n",
    "    best_params: dict = {'name': 'DT', 'metric': metric, 'params': ()}\n",
    "    best_performance: float = 0.0\n",
    "\n",
    "    values: dict = {}\n",
    "    for c in criteria:\n",
    "        y_tst_values: list[float] = []\n",
    "        for d in depths:\n",
    "            clf = DecisionTreeClassifier(max_depth=d, criterion=c, min_impurity_decrease=0)\n",
    "            clf.fit(trnX, trnY)\n",
    "            prdY: array = clf.predict(tstX)\n",
    "            eval: float = CLASS_EVAL_METRICS[metric](tstY, prdY)\n",
    "            y_tst_values.append(eval)\n",
    "            if eval - best_performance > DELTA_IMPROVE:\n",
    "                best_performance = eval\n",
    "                best_params['params'] = (c, d)\n",
    "                best_model = clf\n",
    "            # print(f'DT {c} and d={d}')\n",
    "        values[c] = y_tst_values\n",
    "    print(f'DT best with {best_params['params'][0]} and d={best_params['params'][1]}')\n",
    "    plot_multiline_chart(depths, values, title=f'DT Models ({metric})', xlabel='d', ylabel=metric, percentage=True)\n",
    "\n",
    "    return best_model, best_params\n",
    "\n",
    "file_tag = 'stroke'\n",
    "train_filename = 'data/stroke_train_smote.csv'\n",
    "test_filename = 'data/stroke_test.csv'\n",
    "target = 'stroke'\n",
    "eval_metric = 'accuracy'\n",
    "\n",
    "trnX, tstX, trnY, tstY, labels, vars = read_train_test_from_files(train_filename, test_filename, target)\n",
    "print(f'Train#={len(trnX)} Test#={len(tstX)}')\n",
    "print(f'Labels={labels}')\n",
    "\n",
    "figure()\n",
    "best_model, params = trees_study(trnX, trnY, tstX, tstY, d_max=25, metric=eval_metric)\n",
    "savefig(f'images/{file_tag}_dt_{eval_metric}_study.png')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a060b3",
   "metadata": {},
   "source": [
    "<h3>Best model performance</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a53348",
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_trn: array = best_model.predict(trnX)\n",
    "prd_tst: array = best_model.predict(tstX)\n",
    "figure()\n",
    "plot_evaluation_results(params, trnY, prd_trn, tstY, prd_tst, labels)\n",
    "savefig(f'images/{file_tag}_dt_{params[\"name\"]}_best_{params[\"metric\"]}_eval.png')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc06dca",
   "metadata": {},
   "source": [
    "<h3>Variables importance</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5769c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from matplotlib.pyplot import imread, imshow, axis\n",
    "from subprocess import call\n",
    "\n",
    "tree_filename: str = f\"images/{file_tag}_dt_{eval_metric}_best_tree\"\n",
    "max_depth2show = 3\n",
    "st_labels: list[str] = [str(value) for value in labels]\n",
    "\n",
    "dot_data: str = export_graphviz(\n",
    "    best_model,\n",
    "    out_file=tree_filename + \".dot\",\n",
    "    max_depth=max_depth2show,\n",
    "    feature_names=vars,\n",
    "    class_names=st_labels,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    impurity=False,\n",
    "    special_characters=True,\n",
    "    precision=2,\n",
    ")\n",
    "# Convert to png\n",
    "call(\n",
    "    [\"dot\", \"-Tpng\", tree_filename + \".dot\", \"-o\", tree_filename + \".png\", \"-Gdpi=600\"]\n",
    ")\n",
    "\n",
    "figure(figsize=(14, 6))\n",
    "imshow(imread(tree_filename + \".png\"))\n",
    "axis(\"off\")\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3ac0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "figure(figsize=(14, 6))\n",
    "plot_tree(\n",
    "    best_model,\n",
    "    max_depth=max_depth2show,\n",
    "    feature_names=vars,\n",
    "    class_names=st_labels,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    impurity=False,\n",
    "    precision=2,\n",
    ")\n",
    "savefig(tree_filename + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d11b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argsort\n",
    "from dslabs_functions import plot_horizontal_bar_chart\n",
    "\n",
    "importances = best_model.feature_importances_\n",
    "indices: list[int] = argsort(importances)[::-1]\n",
    "elems: list[str] = []\n",
    "imp_values: list[float] = []\n",
    "for f in range(len(vars)):\n",
    "    elems += [vars[indices[f]]]\n",
    "    imp_values += [importances[indices[f]]]\n",
    "    print(f\"{f+1}. {elems[f]} ({importances[indices[f]]})\")\n",
    "\n",
    "figure()\n",
    "plot_horizontal_bar_chart(\n",
    "    elems,\n",
    "    imp_values,\n",
    "    title=\"Decision Tree variables importance\",\n",
    "    xlabel=\"importance\",\n",
    "    ylabel=\"variables\",\n",
    "    percentage=True,\n",
    ")\n",
    "savefig(f\"images/{file_tag}_dt_{eval_metric}_vars_ranking.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5225d1",
   "metadata": {},
   "source": [
    "<h3>Overfitting study</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4443580",
   "metadata": {},
   "outputs": [],
   "source": [
    "crit: Literal[\"entropy\", \"gini\"] = params[\"params\"][0]\n",
    "d_max = 25\n",
    "depths: list[int] = [i for i in range(2, d_max + 1, 1)]\n",
    "y_tst_values: list[float] = []\n",
    "y_trn_values: list[float] = []\n",
    "acc_metric = \"accuracy\"\n",
    "for d in depths:\n",
    "    clf = DecisionTreeClassifier(max_depth=d, criterion=crit, min_impurity_decrease=0)\n",
    "    clf.fit(trnX, trnY)\n",
    "    prd_tst_Y: array = clf.predict(tstX)\n",
    "    prd_trn_Y: array = clf.predict(trnX)\n",
    "    y_tst_values.append(CLASS_EVAL_METRICS[acc_metric](tstY, prd_tst_Y))\n",
    "    y_trn_values.append(CLASS_EVAL_METRICS[acc_metric](trnY, prd_trn_Y))\n",
    "\n",
    "figure()\n",
    "plot_multiline_chart(\n",
    "    depths,\n",
    "    {\"Train\": y_trn_values, \"Test\": y_tst_values},\n",
    "    title=f\"DT overfitting study for {crit}\",\n",
    "    xlabel=\"max_depth\",\n",
    "    ylabel=str(eval_metric),\n",
    "    percentage=True,\n",
    ")\n",
    "savefig(f\"images/{file_tag}_dt_{eval_metric}_overfitting.png\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
